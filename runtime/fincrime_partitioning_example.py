# -*- coding: utf-8 -*-
"""fincrime-partitioning-example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCteGGNZlOMf3BX_hyRnEii8h_f-9H8_

# PETs Prize Challenge

Financial Crime Track Partitioning Example

Last Updated: December 2022

This notebook demonstrates how to generate an example partition for the Financial Crime Track of the PETs Prize Challenge:
- [U.S. Link](https://www.drivendata.org/competitions/105/nist-federated-learning-2-financial-crime-federated/)
- [U.K. Link](https://www.drivendata.org/competitions/140/uk-federated-learning-2-financial-crime-federated/)
 
The partitions should be organized in a `data` directory following the schema specified in the [runtime repo](https://github.com/drivendataorg/pets-prize-challenge-runtime#data-1). The following example shows what the `data` directory would look like with 3 partitions (one `swift` partition and two `bank` partitions):

```
data/fincrime/scenario01
├── test
│   ├── bank01
│   │   └── bank_dataset.csv
│   ├── bank02
│   │   └── bank_dataset.csv
│   ├── partitions.json
│   └── swift
│       ├── predictions_format.csv
│       └── swift_transaction_test_dataset.csv
└── train
    ├── bank01
    │   └── bank_dataset.csv
    ├── bank02
    │   └── bank_dataset.csv
    ├── partitions.json
    └── swift
        └── swift_transaction_train_dataset.csv
```

For more information on how to generate and test your federated solutions, check out the federated code submission pages:
- [U.S. Federated Code Submission Page](https://www.drivendata.org/competitions/105/nist-federated-learning-2-financial-crime-federated/page/587/)
- [U.K. Federated Code Submission Page](https://www.drivendata.org/competitions/140/uk-federated-learning-2-financial-crime-federated/page/638/)

Let's get started!
"""

from collections import defaultdict
from pathlib import Path
import shutil
import tarfile

import numpy as np
import pandas as pd

"""## Fetch and extract data"""

# Read from local data path
DATA = Path.cwd() / "../data/"
FINAL = DATA / "final" / "phase_2" / "financial_crime" / "public"
print(*[p.name for p in FINAL.iterdir()], sep="\n")

# Extract files to local directory
extracted_files = []

for p in FINAL.iterdir():
    tf = tarfile.open(p, mode="r:gz")
    members = tf.getnames()
    for member in members:
        if member.endswith(".csv"):
            tf.extract(member)
            extracted_files.append(member)

extracted_files

# Define write paths for partitions
OUT_DIR = DATA / "fincrime" / "scenario01"
TEST = OUT_DIR / "test"
TRAIN = OUT_DIR / "train"

"""### Copy train and test datasets to SWIFT Partitions"""

# copy train dataset to `swift` partitions
(TEST / "swift").mkdir(exist_ok=True, parents=True)
(TRAIN / "swift").mkdir(exist_ok=True, parents=True)

train_pth = shutil.copy(
    Path(Path.cwd() / "dev_swift_transaction_train_dataset.csv"),
    TRAIN / "swift" / "swift_transaction_train_dataset.csv",
)
print(f"Finished writing {train_pth.relative_to(train_pth.parents[3])}...")

"""In the test environment, the `Label` column will not available in the test data (`swift_transaction_test_dataset.csv`). Additionally, a `predictions_format.csv` will be provided to specify the index and columns of your predictions. You can find more details about the predictions format [here](https://www.drivendata.org/competitions/105/nist-federated-learning-2-financial-crime-federated/page/587/#predictions-format).

Let's generate and partition those two files now.
"""

test_df = pd.read_csv(
    Path.cwd() / "dev_swift_transaction_test_dataset.csv", index_col="MessageId"
)
label_col = "Label"

# create pred format df and set all predictions to 0.5
test_df["Score"] = 0.5
pred_format_df = test_df[["Score"]].copy()

# create test df from remaining columns
test_df = test_df.drop(columns=[label_col, "Score"])

pred_format_df

test_df

# write out to `swift` partition
test_path = TEST / "swift" / "swift_transaction_test_dataset.csv"
pred_path = TEST / "swift" / "predictions_format.csv"

test_df.to_csv(test_path)
pred_format_df.to_csv(pred_path)

print(f"Finished writing {test_path.relative_to(test_path.parents[3])}...")
print(f"Finished writing {pred_path.relative_to(test_path.parents[3])}...")

"""### Randomly partition banks

There are two large receiving banks in this dataset: `BANKUSUS` and `BANKDEDE`. These two banks will always be in separate partitions.

The rest of the banks will be randomly partitioned. If there are 3 or fewer bank partitions, some sending banks will share a partition with the receiving banks. If there are 4 or more bank partitions, sending banks will be randomly partitioned among the non-receiving bank partitions.

In this example, we will be creating four bank partitions in addition to the SWIFT partition (for a total of 5 partitions). The receiving banks will each occupy one partition. The sending banks will be randomly divided among the remaining two partitions.

Let's take a look at the bank dataset.
"""

bank_df = pd.read_csv(Path.cwd() / "dev_bank_dataset.csv")
bank_df.head()

bank_df.Bank.nunique()

bank_df.Bank.value_counts()

# Set seed
np.random.seed(8)

# create partition map with two receiving banks
partition_to_banks = defaultdict(set)
partition_to_banks["bank01"] = {"BANKUSUS"}
partition_to_banks["bank02"] = {"BANKDEDE"}

# randomly assign sending banks to remaining partitions
N_PARTITIONS = 2
banks = bank_df[~bank_df.Bank.isin(partition_to_banks)].Bank.unique()

# partition names are 1 indexed. Leave first two partitions for receiving banks.
partition_ids = [(i % N_PARTITIONS) + 3 for i in range(len(banks))]
np.random.shuffle(partition_ids)
bank_to_partition = dict(zip(banks, partition_ids))

# invert dictionary
for bank, partition in bank_to_partition.items():
    partition_to_banks[f"bank{partition:02}"].add(bank)

# inspect
for partition in sorted(partition_to_banks):
    print(f"{partition}: {len(partition_to_banks[partition])} bank(s)")

"""### Partition bank dataset"""

for partition_name, bank_set in partition_to_banks.items():
    subset = bank_df[bank_df["Bank"].isin(bank_set)]
    for out_dir in [TRAIN, TEST]:
        out_file = out_dir / partition_name / "bank_dataset.csv"
        out_file.parent.mkdir(exist_ok=True, parents=True)
        print(f"Writing {out_file.relative_to(out_file.parents[3])}...")
        subset.to_csv(out_file)

"""### Clean up extracted files"""

for fn in extracted_files:
    (Path.cwd() / fn).unlink()

"""### Inspect partitioned files"""

print(*[f"{f.relative_to(OUT_DIR)}" for f in OUT_DIR.rglob("*.csv")], sep="\n")